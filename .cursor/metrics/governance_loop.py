"""
CEB-E Governance Loop

–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ governance –ø—Ä–æ—Ñ–∏–ª—è.
"""

import json
import yaml
import argparse
from pathlib import Path
from datetime import datetime
import os


def apply_governance(results_path: Path = None, auto_upgrade: bool = True) -> dict:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç governance –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞."""
    if results_path is None:
        results_path = Path(".cursor/audit/audit_report.json")
    
    if not results_path.exists():
        print(f"‚ö†Ô∏è  –§–∞–π–ª –∞—É–¥–∏—Ç–∞ {results_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞—É–¥–∏—Ç —Å–Ω–∞—á–∞–ª–∞.")
        return {"status": "error", "message": "audit report not found"}
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞
    data = json.loads(results_path.read_text(encoding="utf-8"))
    
    score = data.get("score", 0)
    level = data.get("level", 0)
    reliability = data.get("ai_reliability_index", 0.0)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è –∑—Ä–µ–ª–æ—Å—Ç–∏ –∏ –º–µ—Ç—Ä–∏–∫
    # Safe-mode —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ reliability –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è (< 0.5)
    if auto_upgrade and reliability < 0.5:
        profile = "safe-mode"
        description = "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º: –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∞—è, —Ç—Ä–µ–±—É—é—Ç—Å—è –º–µ—Ä—ã"
    elif level >= 5:
        profile = "self-adaptive"
        description = "–ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–∞–º–æ–ø—Ä–∏—Å–ø–æ—Å–∞–±–ª–∏–≤–∞—é—â–∞—è—Å—è —Å–∏—Å—Ç–µ–º–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"
    elif level >= 4:
        profile = "automated"
        description = "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º"
    elif level >= 3:
        profile = "pro"
        description = "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏"
    elif level >= 2:
        profile = "foundational"
        description = "–ë–∞–∑–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º"
    else:
        profile = "initial"
        description = "–ù–∞—á–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
    
    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Ñ–∏–ª—å governance
    governance_dir = Path(".cursor/governance")
    governance_dir.mkdir(parents=True, exist_ok=True)
    
    profile_path = governance_dir / "profile.yaml"
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
    current_profile = None
    if profile_path.exists():
        try:
            current_data = yaml.safe_load(profile_path.read_text(encoding="utf-8"))
            current_profile = current_data.get("active_profile")
        except Exception:
            pass
    
    profile_data = {
        "current_level": level,
        "target_level": min(5, level + 1),
        "active_profile": profile,
        "previous_profile": current_profile,
        "description": description,
        "last_audit_score": score,
        "last_audit_level": level,
        "last_audit_date": data.get("date", ""),
        "reliability_index": reliability,
        "context_hit_rate": data.get("context_hit_rate", 0),
        "goals": {
            "enable_rules_engine": level >= 2,
            "enable_validation": level >= 3,
            "enable_mcp_gateway": level >= 3,
            "enable_governance_loop": level >= 3,
        },
        "governance_policies": [
            {
                "name": "Safety Mode",
                "condition": "reliability_index < 0.5",
                "action": "downgrade_to_safe_mode",
                "active": reliability < 0.5,
            },
            {
                "name": "Auto Upgrade",
                "condition": "audit_score >= 70",
                "action": "upgrade_to_automated",
                "active": score >= 70,
            },
            {
                "name": "Self-Adaptive",
                "condition": "audit_score >= 90 and reliability_index >= 0.95",
                "action": "enable_self_adaptive",
                "active": score >= 90 and reliability >= 0.95,
            },
            {
                "name": "MCP Service Failure",
                "condition": "mcp_governance.failed_services.length > 0",
                "action": "lower_mcp_priority",
                "description": "–ü–æ–Ω–∏–∑–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–∏ —Å–±–æ—è—Ö MCP-—Å–µ—Ä–≤–∏—Å–æ–≤",
                "active": False,  # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è —á–µ—Ä–µ–∑ validate-mcp playbook
            },
        ],
        "mcp_governance": {
            "last_check": None,
            "alerts": [],
            "failed_services": [],
            "warnings": [],
            "healthy_count": 0,
            "enabled_count": 0,
        },
        "osint_governance": {
            "avg_deepconf_confidence": None,
            "missions_completed": 0,
            "knowledge_health": "unknown",
            "auto_regeneration_active": False,
            "last_curation": None,
        },
        "config": {
            "auto_fix": level >= 3 and reliability >= 0.7,
            "strict_validation": level >= 4,
            "adaptive_rules": level >= 5,
            "metrics_collection": level >= 2,
            "auto_audit": level >= 4,
            "osint_auto_regeneration": level >= 5,
            "memory_auto_curation": level >= 5,
            "deepconf_feedback_loop": level >= 5,
            "methodology_compliance": level >= 5,
        },
        "methodology_compliance": {
            "active": False,
            "last_check": None,
            "compliance_score": None,
            "status": "unknown",
        },
        "metadata": {
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "version": "1.0",
        },
    }
    
    with profile_path.open("w", encoding="utf-8") as f:
        yaml.safe_dump(profile_data, f, allow_unicode=True, default_flow_style=False)
    
    print(f"\n{'='*60}")
    print(f"Governance Loop Applied")
    print(f"{'='*60}")
    print(f"–ü—Ä–æ—Ñ–∏–ª—å: {profile}")
    print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}")
    print(f"–£—Ä–æ–≤–µ–Ω—å –∑—Ä–µ–ª–æ—Å—Ç–∏: {level}")
    print(f"–ë–∞–ª–ª –∞—É–¥–∏—Ç–∞: {score}")
    print(f"AI Reliability: {reliability:.2f}")
    print(f"Context Hit Rate: {data.get('context_hit_rate', 0):.2f}")
    
    if current_profile and current_profile != profile:
        print(f"üîÑ –ü—Ä–æ—Ñ–∏–ª—å –∏–∑–º–µ–Ω—ë–Ω: {current_profile} ‚Üí {profile}")
    elif not current_profile:
        print(f"‚úÖ –ü—Ä–æ—Ñ–∏–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {profile}")
    
    print(f"\n–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {profile_path}")
    print(f"{'='*60}\n")
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ Supabase (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
    if os.getenv("DB_BACKEND") == "supabase":
        try:
            push_metrics_to_supabase(reliability, data.get("context_hit_rate", 0))
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to push metrics to Supabase: {e}")
    
    return {
        "status": "success",
        "profile": profile,
        "profile_path": str(profile_path),
        "config": profile_data,
    }


def push_metrics_to_supabase(ai_reliability: float, context_hit_rate: float):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ Governance –≤ Supabase.
    
    Args:
        ai_reliability: AI Reliability Index
        context_hit_rate: Context Hit Rate
    """
    try:
        from src.storage.db import get_db
        
        db = get_db()
        
        metrics_to_push = {
            "ai_reliability": ai_reliability,
            "context_hit_rate": context_hit_rate,
        }
        
        for metric_name, value in metrics_to_push.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            existing = db.select("metrics", filters={"metric_name": metric_name}, limit=1)
            
            metric_data = {
                "metric_name": metric_name,
                "metric_value": float(value),
                "updated_at": datetime.now().isoformat(),
            }
            
            if existing:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–µ—Ç—Ä–∏–∫—É
                db.update("metrics", existing[0]["id"], metric_data)
            else:
                # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É
                db.insert("metrics", metric_data)
        
        print(f"‚úÖ Metrics pushed to Supabase: {list(metrics_to_push.keys())}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to push metrics: {e}")
        # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É


def insert_metric(metric_name: str, value: float):
    """
    –í—Å—Ç–∞–≤–ª—è–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫—É –≤ Supabase.
    
    Args:
        metric_name: –ò–º—è –º–µ—Ç—Ä–∏–∫–∏
        value: –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    """
    try:
        from src.storage.db import get_db
        
        db = get_db()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        existing = db.select("metrics", filters={"metric_name": metric_name}, limit=1)
        
        metric_data = {
            "metric_name": metric_name,
            "metric_value": float(value),
            "updated_at": datetime.now().isoformat(),
        }
        
        if existing:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–µ—Ç—Ä–∏–∫—É
            db.update("metrics", existing[0]["id"], metric_data)
        else:
            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É
            db.insert("metrics", metric_data)
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to insert metric {metric_name}: {e}")


def main():
    parser = argparse.ArgumentParser(description="CEB-E Governance Loop")
    parser.add_argument(
        "--apply",
        choices=["results"],
        help="–ü—Ä–∏–º–µ–Ω–∏—Ç—å governance –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞",
    )
    parser.add_argument(
        "--push-metrics",
        action="store_true",
        help="–û—Ç–ø—Ä–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ Supabase",
    )
    parser.add_argument(
        "--results",
        type=Path,
        default=Path(".cursor/audit/audit_report.json"),
        help="–ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞—É–¥–∏—Ç–∞",
    )
    
    args = parser.parse_args()
    
    if args.push_metrics:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –∞—É–¥–∏—Ç–∞ –∏–ª–∏ cursor-metrics.json
        try:
            audit_path = Path(".cursor/audit/audit_report.json")
            if audit_path.exists():
                audit_data = json.loads(audit_path.read_text(encoding="utf-8"))
                reliability = audit_data.get("ai_reliability_index", 0.0)
                context_hit = audit_data.get("context_hit_rate", 0.0)
            else:
                # –ü—Ä–æ–±—É–µ–º –∏–∑ cursor-metrics.json
                metrics_path = Path("cursor-metrics.json")
                if metrics_path.exists():
                    metrics_data = json.loads(metrics_path.read_text(encoding="utf-8"))
                    gov_metrics = metrics_data.get("metrics", {}).get("governance", {})
                    reliability = gov_metrics.get("reliability_index", 0.0)
                    context_hit = gov_metrics.get("context_hit_rate", 0.0)
                else:
                    reliability = 0.0
                    context_hit = 0.0
            
            push_metrics_to_supabase(reliability, context_hit)
            print("‚úÖ Metrics pushed to Supabase")
            return 0
        except Exception as e:
            print(f"‚ùå Failed to push metrics: {e}")
            return 1
    
    if args.apply == "results":
        result = apply_governance(args.results)
        return 0 if result["status"] == "success" else 1
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result = apply_governance()
        return 0 if result["status"] == "success" else 1


if __name__ == "__main__":
    exit(main())

